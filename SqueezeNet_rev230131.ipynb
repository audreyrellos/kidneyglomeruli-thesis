{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# required libraries & dataset\n",
        "\n",
        "#!curl -L \"https://www.dropbox.com/s/ypvbhkgt4sb40sy/dataset_b.zip?dl=0\" > dataset_b.zip; unzip dataset_b.zip; rm dataset_b.zip\n",
        "#!pip install livelossplot"
      ],
      "metadata": {
        "id": "g5mqjpR1Wlz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaZYYGQzEdtT"
      },
      "outputs": [],
      "source": [
        "# Importing dependencies\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import keras\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, BatchNormalization\n",
        "from keras.layers import concatenate, GlobalAvgPool2D, Dropout, DepthwiseConv2D, ReLU, Activation\n",
        "from keras.models import Model\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting TPU or CPU/GPU strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    print(\"Device:\", tpu.master())\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    print(\"Using CPU/GPU strategy\")\n",
        "    strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "EMVQztwaPlPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size and Input shape \n",
        "IMG_SIZE = 224\n",
        "width = 224\n",
        "height = 224\n",
        "input_shape = (height, width, 3)\n",
        "seed = 1432\n",
        "class_mode = 'binary'\n",
        "n_classes = 1"
      ],
      "metadata": {
        "id": "_Tkk4DaIV9Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training/testing directory. Change as needed\n",
        "TRAIN_DIR = \"/content/train\"\n",
        "TEST_DIR = \"/content/test\"\n",
        "VALID_DIR = \"/content/valid\"\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "HgxgSehLkNRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
        "test_imgs = [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
        "valid_imgs = [VALID_DIR+i for i in os.listdir(VALID_DIR)]"
      ],
      "metadata": {
        "id": "XyGuJjdiwoJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAIN_DIR,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        seed=seed,\n",
        "        class_mode=class_mode)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        VALID_DIR,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        seed=seed,\n",
        "        class_mode=class_mode)\n",
        "\n",
        "classnames = train_generator.class_indices\n",
        "\n",
        "print(classnames)"
      ],
      "metadata": {
        "id": "949ZBq0sTkwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image augmentation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(factor=0.15),\n",
        "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "        layers.RandomFlip(),\n",
        "        layers.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")"
      ],
      "metadata": {
        "id": "DlBdmlIyOZy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SqueezeNet Model\n",
        "def SqueezeNet(input_shape, num_classes):\n",
        "  def fire(x, fs, fe):\n",
        "    s = Conv2D(fs, 1, activation='relu')(x)\n",
        "    e1 = Conv2D(fe, 1, activation='relu')(s)\n",
        "    e3 = Conv2D(fe, 3, padding='same', activation='relu')(s)\n",
        "    output = concatenate([e1,e3])\n",
        "    return output\n",
        "\n",
        "  input = Input(input_shape)\n",
        "  x = Conv2D(96, 7, strides=2, padding='same', activation='relu')(input)\n",
        "  x = MaxPool2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "  x = fire(x, 16, 64)\n",
        "  x = fire(x, 16, 64)\n",
        "  x = fire(x, 16, 128)\n",
        "  x = MaxPool2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "  x = fire(x, 32, 128)\n",
        "  x = fire(x, 48, 192)\n",
        "  x = fire(x, 48, 192)\n",
        "  x = fire(x, 64, 256)\n",
        "  x = MaxPool2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "  x = fire(x, 64, 256)\n",
        "  x = Conv2D(n_classes, 1)(x)\n",
        "\n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  output = Activation('sigmoid')(x)\n",
        "\n",
        "  model = Model(input, output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "a3Wy3JS5OaIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = SqueezeNet(input_shape, n_classes)"
      ],
      "metadata": {
        "id": "ih2zca1UOmNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing pre-trained layers\n",
        "for layers in (model.layers)[:16]:\n",
        "  layers.trainable= False"
      ],
      "metadata": {
        "id": "dF_x2QUxOmbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of trainable layers:', len(model.trainable_weights))"
      ],
      "metadata": {
        "id": "LnvuMdxlfOeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modifying last layer, needs rework\n",
        "X=Flatten()(model.output)\n",
        "predictions=Dense(1,activation='sigmoid')(X)\n",
        "squeezenetmodel_final= Model(model.input, predictions)"
      ],
      "metadata": {
        "id": "DqzOTjFgOmpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Summary\n",
        "squeezenetmodel_final.summary()"
      ],
      "metadata": {
        "id": "GGUmQv9rPO-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilation\n",
        "\n",
        "learning_rate = 0.0001\n",
        "epochs= 100\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate, decay=learning_rate/epochs)\n",
        "\n",
        "squeezenetmodel_final.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy',\n",
        "             tf.keras.metrics.Precision(),\n",
        "             tf.keras.metrics.Recall()])\n",
        "\n",
        "squeezenetmodel_final.summary()"
      ],
      "metadata": {
        "id": "Lb3GeuM8PPNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "from livelossplot import PlotLossesKeras\n",
        "from livelossplot.keras import PlotLossesCallback\n",
        "\n",
        "plot_loss_1 = PlotLossesCallback()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"squeezenet_rev230131.h5\",\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=False,\n",
        "                             save_weights_only=False,\n",
        "                             mode='auto',\n",
        "                             save_freq=1)\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss',\n",
        "                      min_delta=0,\n",
        "                      patience=10,\n",
        "                      verbose=1, \n",
        "                      restore_best_weights=True,\n",
        "                      mode='auto')"
      ],
      "metadata": {
        "id": "ff-xkbF4fSx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "squeezenet_hist=squeezenetmodel_final.fit(train_generator,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=validation_generator, \n",
        "                        callbacks= [checkpoint, early, plot_loss_1],\n",
        "                        verbose=1)"
      ],
      "metadata": {
        "id": "N82tLhj7fZN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/squeezenet_rev230131.h5')"
      ],
      "metadata": {
        "id": "_8RYhFkIA0Mn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
